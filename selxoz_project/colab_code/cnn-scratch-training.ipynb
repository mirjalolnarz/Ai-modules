{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "\n",
    "# #Path for training and testing directory\n",
    "# drive.mount('/content/drive')\n",
    "# dataset_path = \"/content/drive/My Drive/Colab Notebooks/Agrar_uchun/v\"\n",
    "# dataset = torchvision.datasets.ImageFolder(root = dataset_path, transform=transformer)\n",
    "\n",
    "dataset_path_local = r'C:\\Users\\mirja\\myenv\\DjangoAPI\\selxoz_project\\edited_image'\n",
    "dataset = torchvision.datasets.ImageFolder(root = dataset_path_local, transform=transformer)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# train_path=dataset_path\n",
    "# test_path=dataset_path\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #categories\n",
    "# root = pathlib.Path(dataset_path)\n",
    "\n",
    "root = pathlib.Path(dataset_path_local)\n",
    "classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Network\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ConvNet,self).__init__()\n",
    "\n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "\n",
    "        #Input shape= (256,3,256, 256)\n",
    "\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,12,256, 256)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Shape= (256,12,256, 256)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (256,12,256, 256)\n",
    "\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (256,12,128,128)\n",
    "\n",
    "\n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,20,128,128)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (256,20,128,128)\n",
    "\n",
    "\n",
    "\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,32,128,128)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (256,32,128,128)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (256,32,128,128)\n",
    "\n",
    "\n",
    "        self.fc=nn.Linear(in_features=128 * 128 * 32,out_features=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "        #Feed forwad function\n",
    "\n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "\n",
    "        output=self.pool(output)\n",
    "\n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "\n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "\n",
    "\n",
    "            #Above output will be in matrix form, with shape (256,32,128, 128)\n",
    "\n",
    "        output=output.view(-1,32*128*128)\n",
    "\n",
    "\n",
    "        output=self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the size of training and testing images\n",
    "# train_count=len(glob.glob(train_path+'/**/*.JPG'))\n",
    "# test_count=len(glob.glob(test_path+'/**/*.jpg'))\n",
    "train_count=len(train_dataset)\n",
    "test_count=len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 200\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(125.5011) Train Accuracy: 0.16625 Test Accuracy: 0.11\n",
      "Epoch: 1 Train Loss: tensor(33.9502) Train Accuracy: 0.38875 Test Accuracy: 0.23\n",
      "Epoch: 2 Train Loss: tensor(13.8202) Train Accuracy: 0.60375 Test Accuracy: 0.25\n",
      "Epoch: 3 Train Loss: tensor(6.6492) Train Accuracy: 0.75625 Test Accuracy: 0.52\n",
      "Epoch: 4 Train Loss: tensor(3.9384) Train Accuracy: 0.8225 Test Accuracy: 0.48\n",
      "Epoch: 5 Train Loss: tensor(2.7900) Train Accuracy: 0.86375 Test Accuracy: 0.665\n",
      "Epoch: 6 Train Loss: tensor(1.3508) Train Accuracy: 0.9225 Test Accuracy: 0.58\n",
      "Epoch: 7 Train Loss: tensor(0.6270) Train Accuracy: 0.95375 Test Accuracy: 0.56\n",
      "Epoch: 8 Train Loss: tensor(0.4157) Train Accuracy: 0.965 Test Accuracy: 0.57\n",
      "Epoch: 9 Train Loss: tensor(0.5458) Train Accuracy: 0.96625 Test Accuracy: 0.615\n"
     ]
    }
   ],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "\n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "\n",
    "\n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "\n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "\n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "\n",
    "    test_accuracy=test_accuracy/test_count\n",
    "\n",
    "\n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "\n",
    "    #Save the best model\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Train Loss: tensor(0.5458) Train Accuracy: 0.96625 Test Accuracy: 0.615\n"
     ]
    }
   ],
   "source": [
    "print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
